{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6d1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c75acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(0) #For webcam\n",
    "\n",
    "#cap.set(3,640)\n",
    "#cap.set(4,480)\n",
    "\n",
    "cap = cv2.VideoCapture(\"../Videos/cars.mp4\") #For video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f932875",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"../YOLO Weights/yolov8n.pt\")\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695eddfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 7 cars, 395.7ms\n",
      "Speed: 11.6ms preprocess, 395.7ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 125.8ms\n",
      "Speed: 2.0ms preprocess, 125.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 116.6ms\n",
      "Speed: 2.0ms preprocess, 116.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 traffic light, 102.1ms\n",
      "Speed: 2.5ms preprocess, 102.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 traffic light, 109.9ms\n",
      "Speed: 2.0ms preprocess, 109.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 1 traffic light, 96.6ms\n",
      "Speed: 2.5ms preprocess, 96.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 107.6ms\n",
      "Speed: 2.1ms preprocess, 107.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 101.8ms\n",
      "Speed: 2.4ms preprocess, 101.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 102.5ms\n",
      "Speed: 2.5ms preprocess, 102.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 97.2ms\n",
      "Speed: 2.1ms preprocess, 97.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 98.9ms\n",
      "Speed: 2.0ms preprocess, 98.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 107.5ms\n",
      "Speed: 2.0ms preprocess, 107.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 97.5ms\n",
      "Speed: 2.1ms preprocess, 97.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 109.8ms\n",
      "Speed: 1.0ms preprocess, 109.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 111.9ms\n",
      "Speed: 1.0ms preprocess, 111.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 109.4ms\n",
      "Speed: 2.6ms preprocess, 109.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 106.7ms\n",
      "Speed: 2.0ms preprocess, 106.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 105.2ms\n",
      "Speed: 3.0ms preprocess, 105.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 109.3ms\n",
      "Speed: 1.0ms preprocess, 109.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 104.1ms\n",
      "Speed: 2.0ms preprocess, 104.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 107.2ms\n",
      "Speed: 1.0ms preprocess, 107.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 108.6ms\n",
      "Speed: 2.0ms preprocess, 108.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 104.9ms\n",
      "Speed: 2.0ms preprocess, 104.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 truck, 1 traffic light, 110.1ms\n",
      "Speed: 1.0ms preprocess, 110.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 1 traffic light, 101.1ms\n",
      "Speed: 2.0ms preprocess, 101.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 truck, 102.0ms\n",
      "Speed: 1.1ms preprocess, 102.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 truck, 1 traffic light, 103.6ms\n",
      "Speed: 2.0ms preprocess, 103.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 1 traffic light, 108.2ms\n",
      "Speed: 4.0ms preprocess, 108.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 traffic light, 107.3ms\n",
      "Speed: 2.2ms preprocess, 107.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 traffic light, 102.1ms\n",
      "Speed: 3.0ms preprocess, 102.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 traffic light, 102.4ms\n",
      "Speed: 1.0ms preprocess, 102.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            #bounding box\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "            #print(x1,y1,x2,y2)\n",
    "            #cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            \n",
    "            w,h=x2-x1,y2-y1\n",
    "            cvzone.cornerRect(img,(x1,y1,w,h))\n",
    "            \n",
    "            #confident\n",
    "            conf=math.ceil((box.conf[0]*100))/100\n",
    "            #print(conf)\n",
    "            #class name\n",
    "            cls = int(box.cls[0])\n",
    "            cvzone.putTextRect(img,f'{classNames[cls]},{conf}',(max(0,x1),max(35,y1)),scale=1.5,thickness=2)\n",
    "    \n",
    "            \n",
    "             \n",
    "    \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Check if the pressed key is ESC (ASCII value 27)\n",
    "        cv2.destroyAllWindows()\n",
    "        break  # Exit the loop if ESC key is pressed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74cf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
